{"cells":[{"cell_type":"markdown","metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false}},"source":["<h2 id=\"about_dataset\">Customer Churn with Logistic Regression</h2>\n","\n","In this notebook, we'll create a Logistic Regression model for a telecommunication company, to predict when its customers will leave for a competitor, so that they can take some action to retain the customers.\n","We will use a historical telecommunications dataset for predicting customer churn.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import pylab as pl\n","import numpy as np\n","import scipy.optimize as opt\n","from sklearn import preprocessing\n","%matplotlib inline\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false}},"source":["###  Load the Churn data \n","Telco Churn is a hypothetical data file from IBM Object Storage."]},{"cell_type":"code","execution_count":null,"metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false}},"outputs":[],"source":["!wget -O ChurnData.csv https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-ML0101EN-SkillsNetwork/labs/Module%203/data/ChurnData.csv"]},{"cell_type":"markdown","metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false}},"source":["## Load Data From CSV File  \n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["churndf = pd.read_csv(\"churndata.csv\")\n","churndf.head()"]},{"cell_type":"markdown","metadata":{},"source":["<h2 id=\"preprocessing\">Data pre-processing and selection</h2>\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["churndf = churndf[['tenure', 'age', 'address', 'income', 'ed', 'employ', 'equip', 'callcard', 'wireless', 'churn']]\n","churndf['churn'] = churndf['churn'].astype('int')\n","churndf.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["x = np.asanyarray(churndf[['tenure', 'age', 'address', 'income', 'ed', 'employ', 'equip']])\n","y = np.asanyarray(churndf[['churn']])\n","\n","print(x[0:5],\"\\n\\n\", y[0:5])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn import preprocessing\n","x = preprocessing.StandardScaler().fit(x).transform(x)\n","x[0:5]"]},{"cell_type":"markdown","metadata":{},"source":["## Train/Test dataset\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.2, random_state=4)\n","print(xtrain.shape, ytrain.shape, xtest.shape, ytest.shape)"]},{"cell_type":"markdown","metadata":{},"source":["<h2 id=\"modeling\">Modeling (Logistic Regression with Scikit-learn)</h2>\n"]},{"cell_type":"markdown","metadata":{},"source":["__Logistic Regression__ from the Scikit-learn package can use different numerical optimizers to find parameters, including ‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’, ‘saga’ solvers.\n","\n","The version of Logistic Regression in Scikit-learn, supports regularization as well. \n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import confusion_matrix\n","logmodel = LogisticRegression(C = 0.01, solver='liblinear')\n","logmodel.fit(xtrain, ytrain)\n","logmodel"]},{"cell_type":"markdown","metadata":{},"source":["<h2 id=\"modeling\">Prediction using test set</h2>\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["yhat = logmodel.predict(xtest)\n","yhat"]},{"cell_type":"markdown","metadata":{},"source":["__predict_proba__  returns estimates for all classes, ordered by the label of classes."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["yhatprob = logmodel.predict_proba(xtest)\n","yhatprob"]},{"cell_type":"markdown","metadata":{},"source":["<h2 id=\"evaluation\">Evaluation</h2>\n"]},{"cell_type":"markdown","metadata":{},"source":["### jaccard index\n","If the entire set of predicted labels for a sample strictly matches with the true set of labels, then the subset accuracy is 1, otherwise it is 0."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.metrics import jaccard_score\n","jaccard_score(ytest, yhat, pos_label=0)"]},{"cell_type":"markdown","metadata":{},"source":["### confusion matrix"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.metrics import classification_report, confusion_matrix\n","import itertools\n","\n","def plot_confusion_matrix(cm, classes, \n","               normalize = False, \n","               title = 'Confusion Matrix', \n","               cmap = plt.cm.Blues):\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis = 1)[:, np.newaxis]\n","        print(\"Normalized matrix\")\n","    else:\n","        print('without normalization')\n","\n","    print(cm)\n","\n","    plt.imshow(cm, interpolation='nearest', cmap = cmap)\n","    plt.title(title)\n","    plt.colorbar()\n","    tickmarks = np.arange(len(classes))\n","    plt.xticks(tickmarks, classes, rotation = 45)\n","    plt.yticks(tickmarks, classes)\n","\n","    fmt = '.2f' if normalize else 'd'\n","    thresh = cm.max() / 2\n","    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","        plt.text(j, i, format(cm[i,j], fmt), \n","                 horizontalalignment = 'center', \n","                 color = 'white' if cm[i,j] > thresh else 'black')\n","    \n","    plt.tight_layout()\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label')\n","\n","print(confusion_matrix(ytest, yhat, labels=[1,0]))\n","#plot_confusion_matrix(confusion_matrix(ytest, yhat, labels = [1, 0]), classes = ['0','1'])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["cnfmatrix = confusion_matrix(ytest, yhat, labels=[1,0])\n","np.set_printoptions(precision=2)\n","\n","plt.figure()\n","plot_confusion_matrix(cnfmatrix, classes=['churn = 1', 'churn = 0'], normalize = False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(classification_report(ytest, yhat))"]},{"cell_type":"markdown","metadata":{},"source":["### log loss"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.metrics import log_loss\n","log_loss(ytest, yhatprob)"]},{"cell_type":"markdown","metadata":{},"source":["<h2 id=\"practice\">Alternate model parameters</h2>\n","We shall rebuild the Logistic Regression model for the same dataset, but this time, we will use different __solver__ and __regularization__ values."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model = LogisticRegression(C=0.008, solver='sag')\n","model.fit(xtrain, ytrain)\n","yhat1 = model.predict(xtest)\n","yhatprob1 = model.predict_proba(xtest)\n","\n","log_loss(ytest, yhatprob1)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.5"}},"nbformat":4,"nbformat_minor":2}
